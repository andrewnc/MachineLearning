{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis\n",
    "    < Andrew Carr >\n",
    "    Math 404\n",
    "    February 7, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time(func, label, train=False, score=False):\n",
    "    \"\"\"simplify timing by adding a function to do it for me.\"\"\"\n",
    "    print(\"\\n{}:\\n\".format(label))\n",
    "    \n",
    "    # determine type of action\n",
    "    if train:\n",
    "        type_of_action = \"train\"\n",
    "    else:\n",
    "        type_of_action = \"test\"\n",
    "        \n",
    "    # run the function\n",
    "    start = time.time()\n",
    "    if train:\n",
    "        func(train_x,train_y)\n",
    "    else:\n",
    "        func(test_x,test_y)\n",
    "    print(\"\\t{} time {}\".format(type_of_action, time.time() - start))\n",
    "    if score:\n",
    "        print(\"\\taccuracy {}\".format(func(test_x, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Code up the Gaussian Discriminant Analysis algorithm.  Your code should have a .fit method that accepts a dataset X,y where y only takes on a finite number of values (classes), the .fit method should train the model (learn the parameters $\\pi_c$, $\\mu_c$, and  $\\Sigma_c$ for each class c, using the standard Gaussian MLE for each $\\mu_c$, and  $\\Sigma_c$ and using the estimate $\\pi_c$ = (#y=c)/N.  Your code should also have a `.predict_proba` method that accepts a data set X' and returns $p(y=c | x)$ for each x in X',  and it should have a `.predict` method that accepts data X' and returns the class prediction $\\hat{y}$ for each x in X' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GDA(object):\n",
    "    \"\"\"Gaussian Discriminant Analysis Classifier Object\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x,y):\n",
    "        \"\"\"Fit a GDA model given features and labels, returns NONE\"\"\"\n",
    "        self.train_x = x\n",
    "        self.train_y = y\n",
    "        self.num_samples,self.num_features = self.train_x.shape\n",
    "        self.classes = list(set(y))\n",
    "        self.stats = {}\n",
    "        # for both classes\n",
    "        for c in self.classes:\n",
    "            features = self.train_x[self.train_y == c]\n",
    "            \n",
    "            # calculate the probability of the class\n",
    "            pi_c = len(features)/len(self.train_x)\n",
    "            \n",
    "            # gather statistics\n",
    "            mean = np.mean(features, axis=0)\n",
    "            cov = np.cov(features,rowvar=False)\n",
    "            \n",
    "            # create\n",
    "            self.stats[str(c)] = [stats.multivariate_normal(mean=mean, cov=cov, allow_singular=True), pi_c]\n",
    "         \n",
    "    def predict_proba(self,x):\n",
    "        \"\"\"Calculate relative probability (doesn't sum to 1) of x over classes, returns matrix of probabilities\"\"\"\n",
    "        self.test_x = x\n",
    "        self.probs = []\n",
    "        \n",
    "        # for all of our data\n",
    "        for instance in self.test_x:\n",
    "            \n",
    "            # get all class probabilities\n",
    "            internal_probs = []\n",
    "            for c in self.classes:\n",
    "                \n",
    "                # gather info from fit and save\n",
    "                norm, pi_c = self.stats[str(c)]\n",
    "                prob = norm.pdf(instance)*pi_c\n",
    "                internal_probs.append(prob)\n",
    "                \n",
    "            self.probs.append(internal_probs/np.sum(internal_probs)) # row normalize to sum to 1\n",
    "        return self.probs\n",
    "                \n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Calculate class prediction of x over classes, returns list of predictions\"\"\"\n",
    "        self.test_x = x\n",
    "        self.prediction = []\n",
    "        # get probabilities\n",
    "        self.predict_proba(x)\n",
    "        \n",
    "        # find the class by taking the argmax, works since these are relative probabilities\n",
    "        self.prediction = np.argmax(self.probs, axis=1)\n",
    "        return self.prediction\n",
    "\n",
    "        \n",
    "    def accuracy(self, y_true,y_pred):\n",
    "        \"\"\"Find accuracy on a test set returns float, this assumes classes are ordered and not randomly ordered\"\"\"\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def score(self, test_x, test_y):\n",
    "        \"\"\"predicts and scores returns float\"\"\"\n",
    "        self.predict(test_x)\n",
    "        return self.accuracy(test_y, self.prediction)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Apply your GDA code to the cancer dataset with an appropriate train-test split and compare the results (train and test speed and test accuracy) to logistic regression and Naive Bayes.  Is one of these much better than the others?  Explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GDA:\n",
      "\n",
      "\ttrain time 0.001970052719116211\n",
      "\n",
      "NB:\n",
      "\n",
      "\ttrain time 0.0013041496276855469\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "\ttrain time 0.004260063171386719\n",
      "\n",
      "GDA:\n",
      "\n",
      "\ttest time 0.013648748397827148\n",
      "\taccuracy 0.9415204678362573\n",
      "\n",
      "NB:\n",
      "\n",
      "\ttest time 0.0005729198455810547\n",
      "\taccuracy 0.9064327485380117\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "\ttest time 0.0003521442413330078\n",
      "\taccuracy 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "gda_clf = GDA()\n",
    "nb_clf = GaussianNB()\n",
    "log_clf = LogisticRegression()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data,data.target, train_size=0.7)\n",
    "\n",
    "get_time(gda_clf.fit, label=\"GDA\", train=True)\n",
    "get_time(nb_clf.fit, label=\"NB\", train=True)\n",
    "get_time(log_clf.fit, label=\"Logistic Regression\", train=True)\n",
    "\n",
    "get_time(gda_clf.score, label=\"GDA\", score=True)\n",
    "get_time(nb_clf.score, label=\"NB\", score=True)\n",
    "get_time(log_clf.score, label=\"Logistic Regression\", score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that they take a similar amount of time to train, with naive bayes being slightly faster. However, both SKlearn packages test much faster, while accuracy goes back and forth depending on the split. In this case my GDA had higher accuracy, but they are comparable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Compare your train and test speed and your test accuracy to the `discriminant_analysis.QuadraticDiscriminantAnalysis` method in scikit learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GDA:\n",
      "\n",
      "\ttrain time 0.0015871524810791016\n",
      "\n",
      "SKlearn QDA:\n",
      "\n",
      "\ttrain time 0.0017061233520507812\n",
      "\n",
      "GDA:\n",
      "\n",
      "\ttest time 0.05335497856140137\n",
      "\taccuracy 0.9415204678362573\n",
      "\n",
      "SKlearn QDA:\n",
      "\n",
      "\ttest time 0.0007081031799316406\n",
      "\taccuracy 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "gda_clf = GDA()\n",
    "sk_gda_clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "get_time(gda_clf.fit, label=\"GDA\", train=True)\n",
    "get_time(sk_gda_clf.fit, label=\"SKlearn QDA\", train=True)\n",
    "\n",
    "get_time(gda_clf.score, label=\"GDA\", score=True)\n",
    "get_time(sk_gda_clf.score, label=\"SKlearn QDA\", score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see, as expected that train time is relatively similar since my code is nice and vectorized for speed. However, test time is very different. There's is much faster and has higher accuracy. This is super interesting to see. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
